{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196b70bc-8d45-44d4-b536-f99a63aaf620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vivgo\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\vivgo\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.0.0-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 5.5/150.0 MB 37.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 17.0/150.0 MB 48.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 29.4/150.0 MB 51.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 41.9/150.0 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 54.5/150.0 MB 55.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 64.5/150.0 MB 53.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 75.8/150.0 MB 53.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 87.0/150.0 MB 53.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 99.1/150.0 MB 53.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 110.4/150.0 MB 53.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 123.7/150.0 MB 54.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 135.0/150.0 MB 54.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  147.3/150.0 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.9/150.0 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 150.0/150.0 MB 49.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1ff693-e05c-402e-92e2-32aeeb20c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2cf44f-caa9-4ff3-9797-f5225ccf565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = pd.read_csv('dfdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a3f83d-2a83-4195-b642-d27a8f6d7d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000000, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df_patient.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01cb699d-c19c-42c0-8bec-5a0a3f4d1cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivgo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\vivgo\\AppData\\Local\\Temp\\ipykernel_6032\\3007792084.py:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_table = pd.concat([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: frac=1e-05, sample_size=1000, test_acc=0.9640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivgo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: frac=0.0001, sample_size=10000, test_acc=0.9784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivgo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: frac=0.001, sample_size=100000, test_acc=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivgo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: frac=0.01, sample_size=1000000, test_acc=0.9916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivgo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: frac=0.1, sample_size=10000000, test_acc=0.9931\n",
      "Error processing frac=1: Unable to allocate 763. MiB for an array with shape (100000000, 1) and data type float64\n",
      "\n",
      "=== Results Summary ===\n",
      "       Model Description Sample Size  Test Accuracy  Time Taken (s)\n",
      "0   XGBoost (frac=1e-05)        1000         0.9640            0.15\n",
      "1  XGBoost (frac=0.0001)       10000         0.9784            0.14\n",
      "2   XGBoost (frac=0.001)      100000         0.9864            0.35\n",
      "3    XGBoost (frac=0.01)     1000000         0.9916            3.50\n",
      "4     XGBoost (frac=0.1)    10000000         0.9931           34.76\n"
     ]
    }
   ],
   "source": [
    "formula = 'outcome ~ pregnant + glucose + pressure + triceps + insulin + mass + pedigree + age'\n",
    "\n",
    "# Define frac values for different sample sizes, starting large and going down\n",
    "frac_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "# Initialize results table\n",
    "results_table = pd.DataFrame(columns=['Model Description', 'Sample Size', 'Test Accuracy', 'Time Taken (s)'])\n",
    "\n",
    "#loop through each frac value\n",
    "for frac in frac_values:\n",
    "    # Subsample the dataset\n",
    "    df_patient_sub = df_patient.sample(frac=frac, random_state=32)\n",
    "    sample_size = len(df_patient_sub)\n",
    "\n",
    "\n",
    "    try:\n",
    "        #patsy dmatrices\n",
    "        Y, X = dmatrices(formula, df_patient_sub)\n",
    "\n",
    "        # Train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            np.ravel(Y),\n",
    "            test_size=0.25,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train model\n",
    "        xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict & evaluate\n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Stop timing\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "\n",
    "        # Append to results table\n",
    "        results_table = pd.concat([\n",
    "            results_table,\n",
    "            pd.DataFrame([{\n",
    "                'Model Description': f'XGBoost (frac={frac})',\n",
    "                'Sample Size': sample_size,\n",
    "                'Test Accuracy': round(test_accuracy, 4),\n",
    "                'Time Taken (s)': round(time_taken, 2)\n",
    "            }])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        print(f\"Done: frac={frac}, sample_size={sample_size}, test_acc={test_accuracy:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing frac={frac}: {e}\")\n",
    "\n",
    "# Final Results\n",
    "print(\"\\n=== Results Summary ===\")\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299b30f-e2f0-4f46-98e6-1396fbed90d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
